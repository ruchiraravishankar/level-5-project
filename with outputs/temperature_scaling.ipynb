{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0xsFqVZGWR0_",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0xsFqVZGWR0_",
    "outputId": "f33e1a64-7971-44a1-9487-7f1f8dea178b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd1ec51",
   "metadata": {
    "id": "bdd1ec51"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import glob\n",
    "import os\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "data_path = '/content/drive/MyDrive/iam_dataset/'\n",
    "save_path = \"/content/drive/MyDrive/iam_dataset/saved_model/\"\n",
    "\n",
    "\n",
    "if not os.path.exists(save_path + \"calibrated_softmax\"):\n",
    "  os.makedirs(save_path + \"calibrated_softmax\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1KbQiXqowSXX",
   "metadata": {
    "id": "1KbQiXqowSXX"
   },
   "outputs": [],
   "source": [
    "!cp /content/drive/MyDrive/iam_dataset/temperature_scaling.py ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Gu_pWqHEvxrE",
   "metadata": {
    "id": "Gu_pWqHEvxrE"
   },
   "outputs": [],
   "source": [
    "# toggle the model for which softmax needs to be calibrated\n",
    "model_node = 1 # options: 1,2,3,4,5,6,7,23 (for model reuse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7191f93b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7191f93b",
    "outputId": "2a5c25d6-4fb6-4b82-8ce2-5a724262e119"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4901, 2)\n"
     ]
    }
   ],
   "source": [
    "labelled_data = np.load(data_path + 'labelled_data.npy')\n",
    "\n",
    "print(labelled_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22206532",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "22206532",
    "outputId": "fd965f1f-b8fb-44ce-bf93-793d26535e63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(693, 2)\n",
      "node 1, class 0 set\n",
      "(196, 2)\n",
      "['000']\n",
      "['085' '118' '150' '151' '152' '153' '154' '155' '202' '203' '204' '205'\n",
      " '206' '207' '208' '209' '247' '248' '273' '274' '315' '332' '333' '334'\n",
      " '335' '336' '337' '338' '339' '340' '341' '342' '343' '344' '345' '346'\n",
      " '347' '348' '349' '384' '415' '551' '552' '567' '588' '634' '635' '670'\n",
      " '671']\n",
      "(49,)\n",
      "49\n",
      "node 1, class 1 set\n",
      "49\n",
      "(49, 4, 2)\n",
      "(196, 2)\n",
      "['085' '118' '150' '151' '152' '153' '154' '155' '202' '203' '204' '205'\n",
      " '206' '207' '208' '209' '247' '248' '273' '274' '315' '332' '333' '334'\n",
      " '335' '336' '337' '338' '339' '340' '341' '342' '343' '344' '345' '346'\n",
      " '347' '348' '349' '384' '415' '551' '552' '567' '588' '634' '635' '670'\n",
      " '671']\n",
      "(392, 2)\n"
     ]
    }
   ],
   "source": [
    "# if model_node is 1,2,3,4...\n",
    "nodes_handled = [1,2,3,4,23]\n",
    "if model_node in nodes_handled:\n",
    "  labelled_data_0 = labelled_data[labelled_data[:,1] == '000']\n",
    "\n",
    "  print(labelled_data_0.shape)\n",
    "\n",
    "  if model_node == 1 or model_node == 23:\n",
    "    labelled_data_0 = labelled_data_0[:196]\n",
    "    print(\"node 1, class 0 set\")\n",
    "  elif model_node == 2:\n",
    "    labelled_data_0 = labelled_data_0[196:(196*2)]\n",
    "    print(\"node 2, class 0 set\")\n",
    "  elif model_node == 3:\n",
    "    labelled_data_0 = labelled_data_0[(196*2):(196*3)]\n",
    "    print(\"node 3, class 0 set\")\n",
    "  elif model_node == 4:\n",
    "    labelled_data_0 = labelled_data_0[:202]\n",
    "    print(\"node 4, class 0 set\")\n",
    "  else:\n",
    "    print(\"model_node not 1,2,3, or 4\")\n",
    "\n",
    "  print(labelled_data_0.shape)\n",
    "\n",
    "  print(np.unique(labelled_data_0[:,1]))\n",
    "\n",
    "  remove_000 = labelled_data[labelled_data[:,1]!='000']\n",
    "\n",
    "  print(np.unique(remove_000[:,1]))\n",
    "  print(np.unique(remove_000[:,1]).shape)\n",
    "\n",
    "  y = [remove_000[remove_000[:,1]==k] for k in np.unique(remove_000[:,1])]\n",
    "  print(len(y))\n",
    "\n",
    "  labelled_data_1 = []\n",
    "\n",
    "  if model_node == 1 or model_node == 23:\n",
    "    for i in y:\n",
    "      labelled_data_1.append(i[:4])\n",
    "    print(\"node 1, class 1 set\")\n",
    "  elif model_node == 2:\n",
    "    for i in y:\n",
    "      labelled_data_1.append(i[5:9])\n",
    "    print(\"node 2, class 1 set\")  \n",
    "  elif model_node == 3:\n",
    "    for i in y:\n",
    "      labelled_data_1.append(i[9:13])\n",
    "    print(\"node 3, class 1 set\")\n",
    "  elif model_node == 4:\n",
    "    for i in range(len(y)):\n",
    "      if i == 0:\n",
    "        labelled_data_1.append(y[i][:10])\n",
    "      else:\n",
    "        labelled_data_1.append(y[i][:4])\n",
    "    print(\"node 4, class 1 set\")\n",
    "  else:\n",
    "    print(\"model_node not 1,2,3, or 4\")\n",
    "\n",
    "  print(len(labelled_data_1))\n",
    "\n",
    "\n",
    "\n",
    "  if model_node == 1 or model_node == 23 or model_node == 2 or model_node == 3:\n",
    "    labelled_data_1 = np.array(labelled_data_1)\n",
    "    print(labelled_data_1.shape)\n",
    "    labelled_data_1=labelled_data_1.reshape(-1,2)\n",
    "  if model_node == 4:\n",
    "    labelled_data_1 = np.concatenate(labelled_data_1)\n",
    "\n",
    "  print(labelled_data_1.shape)\n",
    "  print(np.unique(labelled_data_1[:,1]))\n",
    "\n",
    "\n",
    "  labelled_data_new = np.concatenate((labelled_data_0, labelled_data_1))\n",
    "  np.random.shuffle(labelled_data_new)\n",
    "  print(labelled_data_new.shape) # mix of sentences from writer id 0 and others, labelled\n",
    "\n",
    "else:\n",
    "  print(\"node not handled in this block\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yQnYGOhYBf6c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yQnYGOhYBf6c",
    "outputId": "559c985c-dd1a-4cb7-f871-8c53e73020a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n",
      "1.0\n",
      "<map object at 0x7f45f8cedbd0>\n",
      "0.00166683483940544\n",
      "0.05850089194631425\n",
      "(49,)\n"
     ]
    }
   ],
   "source": [
    "from random import uniform as rand\n",
    "\n",
    "def randConstrained(n, M):\n",
    "    splits = [0] + [rand(0, 1) for _ in range(0,n-1)] + [1]\n",
    "    splits.sort()\n",
    "    diffs = [x - splits[i - 1] for i, x in enumerate(splits)][1:]\n",
    "    result = map(lambda x:x*M, diffs)\n",
    "    return result\n",
    "\n",
    "res = randConstrained(49,1.0)\n",
    "res_list = list(res)\n",
    "# print(sum(list(res)))\n",
    "print(len(res_list))\n",
    "print(sum(res_list))\n",
    "\n",
    "\n",
    "# HERE - work with labelled_data for any sampling work\n",
    "probs = randConstrained(49,1.0)\n",
    "print(probs)\n",
    "probs = list(probs)\n",
    "# print(probs)\n",
    "probs = np.array(probs)\n",
    "print(probs[0])\n",
    "# probs = np.insert(probs, 0, 0.5)\n",
    "print(probs[1])\n",
    "print(probs.shape)\n",
    "def sampling(p, n):\n",
    "  all_1_writers = np.unique(labelled_data[:,1])[np.unique(labelled_data[:,1])!= '000']\n",
    "  ixs = np.arange(49)\n",
    "  return np.array([all_1_writers[np.random.choice(ixs, p=p)] for i in range(n)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wPpjzu-c-NdR",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wPpjzu-c-NdR",
    "outputId": "0ce895d9-f78c-4159-cf83-7c7f8fd4f615"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model node not handled in this block\n"
     ]
    }
   ],
   "source": [
    "if model_node == 5:\n",
    "\n",
    "  label_array = sampling(probs, 200)\n",
    "\n",
    "  labels, counts = np.unique(label_array, return_counts=True)\n",
    "\n",
    "\n",
    "  print(labels, counts)\n",
    "  print(labels.shape)\n",
    "  print(sum(counts))\n",
    "\n",
    "  all_1_data = labelled_data[labelled_data[:,1]!='000']\n",
    "\n",
    "  # all_085 = all_1_data[all_1_data[:,1]=='085']\n",
    "  # print(all_085.shape)\n",
    "\n",
    "  data_list = []\n",
    "  # data_list.append(all_085)\n",
    "  for i in range(len(labels)):\n",
    "    curr = all_1_data[all_1_data[:,1]==labels[i]][:counts[i]]\n",
    "    data_list.append(curr)\n",
    "\n",
    "  print(len(data_list))\n",
    "\n",
    "  out = np.concatenate(data_list)\n",
    "  print(out.shape)\n",
    "  print(\"node 5, class 1 set\")\n",
    "  all_000 = labelled_data[labelled_data[:,1] == '000']\n",
    "  np.random.shuffle(all_000)\n",
    "  all_000 = all_000[:200]\n",
    "  print(all_000.shape)\n",
    "  print(\"node 5, class 0 set\")\n",
    "  labelled_data_new = np.concatenate([all_000, out])\n",
    "  print(labelled_data_new.shape)\n",
    "\n",
    "else:\n",
    "  print(\"model node not handled in this block\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "KEGBAqukAEXg",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KEGBAqukAEXg",
    "outputId": "95e3821a-637b-43a2-a200-61d314167e66"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_node not handled in this block\n"
     ]
    }
   ],
   "source": [
    "nodes = [6,7]\n",
    "if model_node in nodes:\n",
    "  if model_node == 6:\n",
    "    label_array = sampling(probs, 400)\n",
    "    print(\"node 6, class 1 set\")\n",
    "  elif model_node == 7:\n",
    "    label_array = sampling(probs, 200)\n",
    "    print(\"node 7, class 1 set\")\n",
    "  else:\n",
    "    print(\"set model_node to either 6 or 7\")\n",
    "\n",
    "  labels, counts = np.unique(label_array, return_counts=True)\n",
    "\n",
    "  print(labels, counts)\n",
    "  print(labels.shape)\n",
    "  print(sum(counts))\n",
    "\n",
    "  all_1_data = labelled_data[labelled_data[:,1]!='000']\n",
    "\n",
    "  # all_085 = all_1_data[all_1_data[:,1]=='085']\n",
    "  # print(all_085.shape)\n",
    "\n",
    "  data_list = []\n",
    "  # data_list.append(all_085)\n",
    "  for i in range(len(labels)):\n",
    "    curr = all_1_data[all_1_data[:,1]==labels[i]][:counts[i]]\n",
    "    data_list.append(curr)\n",
    "\n",
    "  print(len(data_list))\n",
    "\n",
    "  # lbl_data = np.array(data_list)\n",
    "  out = np.concatenate(data_list)\n",
    "  # lbl_data = lbl_data.flatten()\n",
    "  # print(lbl_data)\n",
    "  print(out.shape)\n",
    "  all_000 = labelled_data[labelled_data[:,1] == '000']\n",
    "  np.random.shuffle(all_000)\n",
    "\n",
    "  if model_node == 6:\n",
    "    all_000 = all_000[:200]\n",
    "    print(\"node 6, class 0 set\")\n",
    "  elif model_node == 7:\n",
    "    all_000 = all_000[:400]\n",
    "    print(\"node 7, class 0 set\")\n",
    "  else:\n",
    "    print(\"set model_node to either 6 or 7\")\n",
    "    \n",
    "  print(all_000.shape)\n",
    "\n",
    "\n",
    "  labelled_data_new = np.concatenate([all_000, out])\n",
    "  print(labelled_data_new.shape)\n",
    "\n",
    "else:\n",
    "  print(\"model_node not handled in this block\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea68409",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2ea68409",
    "outputId": "6ce6ef4b-d2fa-43e7-dcfb-4a9ec85158d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(175,) (130,) (87,) (175,) (130,) (87,)\n"
     ]
    }
   ],
   "source": [
    "# split before augmenting to ensure the sentences are being split and not the augmented samples\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(labelled_data_new[:,0], labelled_data_new[:,1], test_size=0.33, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.33, random_state=42)\n",
    "print(X_train.shape, X_test.shape, X_val.shape, y_train.shape, y_test.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b41601b",
   "metadata": {
    "id": "4b41601b"
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from PIL import Image\n",
    "import random\n",
    "\n",
    "CROP_SIZE = 113\n",
    "NUM_LABELS = 50\n",
    "\n",
    "def get_augmented_sample(sample, label, sample_ratio):\n",
    "    # Get current image details\n",
    "    img = Image.open(sample)\n",
    "    img_width = img.size[0]\n",
    "    img_height = img.size[1]\n",
    "\n",
    "    # Compute resize dimensions such that aspect ratio is maintained\n",
    "    height_fac = CROP_SIZE / img_height\n",
    "    size = (int(img_width * height_fac), CROP_SIZE)\n",
    "\n",
    "    # Resize image \n",
    "    new_img = img.resize((size), Image.ANTIALIAS)\n",
    "    new_img_width = new_img.size[0]\n",
    "    new_img_height = new_img.size[1]\n",
    "\n",
    "    # Generate a random number of crops of size 113x113 from the resized image\n",
    "    x_coord = list(range(0, new_img_width - CROP_SIZE))\n",
    "    num_crops = int(len(x_coord) * sample_ratio)\n",
    "    random_x_coord = random.sample(x_coord, num_crops)\n",
    "    \n",
    "    # Create augmented images (cropped forms) and map them to a label (writer)\n",
    "    images = []\n",
    "    labels = []\n",
    "    for x in random_x_coord:\n",
    "        img_crop = new_img.crop((x, 0, x + CROP_SIZE, CROP_SIZE))\n",
    "        # Transform image to an array of numbers\n",
    "        images.append(np.asarray(img_crop))\n",
    "        labels.append(label)\n",
    "\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55dc6891",
   "metadata": {
    "id": "55dc6891"
   },
   "outputs": [],
   "source": [
    "def augment(data, labels):\n",
    "    augmented_sample_list = []\n",
    "    augmented_label_list = []\n",
    "    for i in range(len(data)):\n",
    "        augmented_samples, augmented_labels = get_augmented_sample(data[i], labels[i],0.1)\n",
    "        augmented_sample_list.append(augmented_samples)\n",
    "        augmented_label_list.append(augmented_labels)\n",
    "    return augmented_sample_list, augmented_label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664668a5",
   "metadata": {
    "id": "664668a5"
   },
   "outputs": [],
   "source": [
    "augsamps, auglbls = augment(X_train, y_train) # returns two lists of arrays\n",
    "augsamps_test, auglbls_test = augment(X_test, y_test)\n",
    "augsamps_val, auglbls_val = augment(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f35824a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2f35824a",
    "outputId": "f8a9d3e9-4dfa-4995-bed6-550331581f3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26085\n",
      "26085\n",
      "19412\n",
      "19412\n",
      "14485\n",
      "14485\n"
     ]
    }
   ],
   "source": [
    "import operator\n",
    "from functools import reduce\n",
    "\n",
    "# flattening the lists\n",
    "aug_samps = reduce(operator.add, augsamps)\n",
    "aug_lbls = reduce(operator.add, auglbls)\n",
    "\n",
    "aug_samps_test = reduce(operator.add, augsamps_test)\n",
    "aug_lbls_test = reduce(operator.add, auglbls_test)\n",
    "\n",
    "aug_samps_val = reduce(operator.add, augsamps_val)\n",
    "aug_lbls_val = reduce(operator.add, auglbls_val)\n",
    "\n",
    "print(len(aug_samps))\n",
    "print(len(aug_lbls))\n",
    "\n",
    "print(len(aug_samps_test))\n",
    "print(len(aug_lbls_test))\n",
    "\n",
    "print(len(aug_samps_val))\n",
    "print(len(aug_lbls_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967237ec",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "967237ec",
    "outputId": "566d5f28-6664-4907-fb1b-e6a1cb506076"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26085, 113, 113)\n",
      "(26085,)\n",
      "(19412, 113, 113)\n",
      "(19412,)\n",
      "(14485, 113, 113)\n",
      "(14485,)\n"
     ]
    }
   ],
   "source": [
    "# converting lists to arrays\n",
    "aug_samps_arr = np.array(aug_samps)\n",
    "aug_lbls_arr = np.array(aug_lbls)\n",
    "aug_samps_arr_test = np.array(aug_samps_test)\n",
    "aug_lbls_arr_test = np.array(aug_lbls_test)\n",
    "aug_samps_arr_val = np.array(aug_samps_val)\n",
    "aug_lbls_arr_val = np.array(aug_lbls_val)\n",
    "\n",
    "print(aug_samps_arr.shape)\n",
    "print(aug_lbls_arr.shape)\n",
    "print(aug_samps_arr_test.shape)\n",
    "print(aug_lbls_arr_test.shape)\n",
    "print(aug_samps_arr_val.shape)\n",
    "print(aug_lbls_arr_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f568281e",
   "metadata": {
    "id": "f568281e",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train = aug_samps_arr\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, CROP_SIZE, CROP_SIZE)\n",
    "X_train = X_train.astype('float16')\n",
    "X_train /= 255.0\n",
    "y_train = aug_lbls_arr\n",
    "\n",
    "\n",
    "X_test = aug_samps_arr_test\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, CROP_SIZE, CROP_SIZE)\n",
    "X_test = X_test.astype('float16')\n",
    "X_test /= 255.0\n",
    "y_test = aug_lbls_arr_test\n",
    "\n",
    "X_val = aug_samps_arr_val\n",
    "X_val = X_val.reshape(X_val.shape[0], 1, CROP_SIZE, CROP_SIZE)\n",
    "X_val = X_val.astype('float16')\n",
    "X_val /= 255.0\n",
    "y_val = aug_lbls_arr_val\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d2904a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e7d2904a",
    "outputId": "7e7d49c0-92b3-4f40-e254-667905f11e82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26085, 1, 113, 113)\n",
      "(26085,)\n",
      "(19412, 1, 113, 113)\n",
      "(19412,)\n",
      "(14485, 1, 113, 113)\n",
      "(14485,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "print(X_val.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a69fdf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "78a69fdf",
    "outputId": "434d95ba-2362-4f28-f6b6-05307aa2fe48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['000' '085' '118' '150' '151' '152' '153' '154' '155' '202' '203' '204'\n",
      " '205' '206' '207' '209' '247' '248' '273' '274' '315' '332' '333' '336'\n",
      " '337' '338' '339' '340' '341' '342' '343' '344' '345' '348' '349' '415'\n",
      " '551' '552' '567' '588' '634' '635' '670' '671']\n",
      "['000' '1']\n",
      "['0' '1']\n",
      "(26085,)\n",
      "[0. 1.]\n"
     ]
    }
   ],
   "source": [
    "new = np.unique(y_train)\n",
    "print(new)\n",
    "\n",
    "y_train[y_train !='000'] = 1\n",
    "new = np.unique(y_train)\n",
    "print(new)\n",
    "\n",
    "y_train[y_train=='000'] = 0\n",
    "new = np.unique(y_train)\n",
    "print(new)\n",
    "\n",
    "print(y_train.shape)\n",
    "\n",
    "y_train = y_train.astype('float16')\n",
    "\n",
    "print(np.unique(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c049e9bb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c049e9bb",
    "outputId": "e2f69631-05b5-464c-88cc-55a572b557a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['000' '085' '118' '150' '151' '152' '153' '154' '155' '202' '207' '208'\n",
      " '209' '247' '273' '315' '332' '333' '334' '335' '336' '337' '338' '341'\n",
      " '342' '343' '344' '345' '346' '347' '349' '384' '415' '551' '552' '567'\n",
      " '634' '635' '670' '671']\n",
      "['000' '1']\n",
      "['0' '1']\n",
      "(19412,)\n",
      "[0. 1.]\n"
     ]
    }
   ],
   "source": [
    "new = np.unique(y_test)\n",
    "print(new)\n",
    "\n",
    "y_test[y_test !='000'] = 1\n",
    "new = np.unique(y_test)\n",
    "print(new)\n",
    "\n",
    "y_test[y_test=='000'] = 0\n",
    "new = np.unique(y_test)\n",
    "print(new)\n",
    "\n",
    "print(y_test.shape)\n",
    "\n",
    "y_test = y_test.astype('float16')\n",
    "\n",
    "print(np.unique(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yfDEMsWkdQmn",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yfDEMsWkdQmn",
    "outputId": "f5d67869-70c6-4eab-b7da-443c0622b3ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['000' '085' '150' '152' '154' '155' '202' '203' '204' '205' '248' '332'\n",
      " '334' '337' '338' '339' '340' '343' '344' '345' '346' '347' '349' '384'\n",
      " '551' '552' '567' '588' '634' '635' '670']\n",
      "['000' '1']\n",
      "['0' '1']\n",
      "(14485,)\n",
      "[0. 1.]\n"
     ]
    }
   ],
   "source": [
    "new = np.unique(y_val)\n",
    "print(new)\n",
    "\n",
    "y_val[y_val !='000'] = 1\n",
    "new = np.unique(y_val)\n",
    "print(new)\n",
    "\n",
    "y_val[y_val=='000'] = 0\n",
    "new = np.unique(y_val)\n",
    "print(new)\n",
    "\n",
    "print(y_val.shape)\n",
    "\n",
    "y_val = y_val.astype('float16')\n",
    "\n",
    "print(np.unique(y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "g1wfoJoZqOOb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g1wfoJoZqOOb",
    "outputId": "21fe210f-1d27-49ba-b2a6-f8df7060787b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "CUDA = torch.cuda.is_available()\n",
    "device = torch.device('cuda' if CUDA else 'cpu')\n",
    "kwargs = {'num_workers': 1, 'pin_memory': True} if CUDA else {}\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09217c4b",
   "metadata": {
    "id": "09217c4b"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "\n",
    "tensor_x_train = torch.Tensor(X_train).type(torch.cuda.FloatTensor) # transform to torch tensor\n",
    "tensor_y_train = torch.Tensor(y_train).type(torch.cuda.FloatTensor).long()\n",
    "\n",
    "\n",
    "\n",
    "# tensor_x_train = torch.Tensor(X_train) # transform to torch tensor\n",
    "# tensor_y_train = torch.Tensor(y_train).long()\n",
    "\n",
    "train_dataset = TensorDataset(tensor_x_train,tensor_y_train) # create your datset\n",
    "train_dataloader = DataLoader(train_dataset,batch_size=16, shuffle=True, drop_last=True) # create your dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DNDz-ofrfkNC",
   "metadata": {
    "id": "DNDz-ofrfkNC"
   },
   "outputs": [],
   "source": [
    "tensor_x_val = torch.Tensor(X_val).type(torch.cuda.FloatTensor) # transform to torch tensor\n",
    "tensor_y_val = torch.Tensor(y_val).type(torch.cuda.FloatTensor).long()\n",
    "# tensor_x_train = torch.Tensor(X_train) # transform to torch tensor\n",
    "# tensor_y_train = torch.Tensor(y_train).long()\n",
    "\n",
    "val_dataset = TensorDataset(tensor_x_val,tensor_y_val) # create your datset\n",
    "val_dataloader = DataLoader(val_dataset,batch_size=16, shuffle=True, drop_last=True) # create your dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c120a864",
   "metadata": {
    "id": "c120a864"
   },
   "outputs": [],
   "source": [
    "tensor_x_test = torch.Tensor(X_test).type(torch.cuda.FloatTensor) # transform to torch tensor\n",
    "tensor_y_test = torch.Tensor(y_test).long().type(torch.cuda.FloatTensor).long()\n",
    "\n",
    "# tensor_x_test = torch.Tensor(X_test) # transform to torch tensor\n",
    "# tensor_y_test = torch.Tensor(y_test).long()\n",
    "\n",
    "test_dataset = TensorDataset(tensor_x_test,tensor_y_test) # create your datset\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False, drop_last=True) # create your dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HOXYkXWgCKt7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HOXYkXWgCKt7",
    "outputId": "d43cb4c8-8e3d-47e2-f40b-faa8f90c2c50"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([26085, 1, 113, 113])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b0ecba",
   "metadata": {
    "id": "63b0ecba"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "class Binary_Classifier(nn.Module): \n",
    "    def __init__(self):\n",
    "        super(Binary_Classifier, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=10, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=3)\n",
    "        self.conv_drop = nn.Dropout2d()\n",
    "        self.conv3 = nn.Conv2d(20, 30, kernel_size=3)\n",
    "        self.fc1 = nn.Linear(4320, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.max_pool2d = nn.MaxPool2d(2)\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.max_pool2d(self.conv1(x)))\n",
    "        x = self.relu(self.max_pool2d(self.conv_drop(self.conv2(x))))\n",
    "        x = self.relu(self.max_pool2d(self.conv_drop(self.conv3(x))))\n",
    "        x = x.view(x.shape[0],-1)\n",
    "        # print(x.shape)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.conv_drop(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d5c074",
   "metadata": {
    "id": "29d5c074"
   },
   "outputs": [],
   "source": [
    "model=Binary_Classifier().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr = 0.001)\n",
    "\n",
    "# import torch.optim.lr_scheduler.StepLR\n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PGBc37Arp5od",
   "metadata": {
    "id": "PGBc37Arp5od"
   },
   "outputs": [],
   "source": [
    "model_node_1 = 'model_3_convs.pt'\n",
    "\n",
    "model_node_2_fc = 'model_tf_3_convs_retrain_last_fc_node2.pt'\n",
    "model_node_2_conv = 'model_tf_3_convs_retrain_last_conv_node2.pt'\n",
    "\n",
    "model_node_3_fc = 'model_tf_3_convs_retrain_last_fc_node3.pt'\n",
    "model_node_3_conv = 'model_tf_3_convs_retrain_last_conv_node3.pt'\n",
    "\n",
    "model_node_4_fc = 'model_3_convs_node_4_fc.pt'\n",
    "model_node_4_conv = 'model_3_convs_node_4_conv.pt'\n",
    "\n",
    "model_node_5_fc = 'model_3_convs_node5_fc.pt'\n",
    "model_node_5_conv = 'model_3_convs_node5_conv.pt'\n",
    "\n",
    "model_node_6_fc = '3convs_node6_fc.pt'\n",
    "model_node_6_conv = '3convs_node6_conv.pt'\n",
    "\n",
    "model_node_7_fc = '3convs_node7_fc.pt'\n",
    "model_node_7_conv = '3convs_node7_conv.pt'\n",
    "\n",
    "model_node2_node3 = 'modelreuse_node2convmodel_retrainedfc_on_node3.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tU-JC4JrtzSQ",
   "metadata": {
    "id": "tU-JC4JrtzSQ"
   },
   "outputs": [],
   "source": [
    "if model_node == 1:\n",
    "  model_path = model_node_1\n",
    "\n",
    "elif model_node == 2:\n",
    "  model_path = model_node_2_conv\n",
    "\n",
    "\n",
    "elif model_node == 3:\n",
    "  model_path = model_node_3_conv\n",
    "\n",
    "\n",
    "elif model_node == 4:\n",
    "  model_path = model_node_4_conv\n",
    "\n",
    "\n",
    "elif model_node == 5:\n",
    "  model_path = model_node_5_conv\n",
    "\n",
    "\n",
    "elif model_node == 6:\n",
    "  model_path = model_node_6_conv\n",
    "\n",
    "elif model_node == 7:\n",
    "  model_path = model_node_7_conv\n",
    "\n",
    "\n",
    "elif model_node == 23:\n",
    "  model_path = model_node2_node3\n",
    "\n",
    "else:\n",
    "  print(\"set model_node variable at the top of the file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qnFjmaPqPwzH",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qnFjmaPqPwzH",
    "outputId": "03ff4701-b1b5-49ec-8dbb-3a11dfb6a91c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint: /content/drive/MyDrive/iam_dataset/saved_model/modelreuse_node2convmodel_retrainedfc_on_node3.pt\n"
     ]
    }
   ],
   "source": [
    "# if os.path.exists(save_path+'/model_3_convs_node6_conv.pt'):\n",
    "try:\n",
    "    print('Loading checkpoint: %s' % save_path + model_path)\n",
    "    path = torch.load(save_path + model_path)\n",
    "    # epoch = path['epoch']\n",
    "    model.load_state_dict(path['model'])\n",
    "    optimizer.load_state_dict(path['optimizer'])\n",
    "except Exception as e:\n",
    "  print(\"nothing happened\")\n",
    "  print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80S98P5hphty",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "80S98P5hphty",
    "outputId": "66aaca47-c65e-4ccb-d076-7e8b10bbd044"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before temperature - NLL: 0.642, ECE: 0.017\n",
      "Optimal temperature: 1.493\n",
      "After temperature - NLL: 0.647, ECE: 0.029\n"
     ]
    }
   ],
   "source": [
    "from temperature_scaling import ModelWithTemperature\n",
    "scaled_model = ModelWithTemperature(model)\n",
    "temp_model = scaled_model.set_temperature(val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "YIRXNtX-v3fR",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YIRXNtX-v3fR",
    "outputId": "ca9ae316-834a-46d8-8f99-6bc974df2bfe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelWithTemperature(\n",
      "  (model): Binary_Classifier(\n",
      "    (conv1): Conv2d(1, 10, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (conv2): Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (conv_drop): Dropout2d(p=0.5, inplace=False)\n",
      "    (conv3): Conv2d(20, 30, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (fc1): Linear(in_features=4320, out_features=1024, bias=True)\n",
      "    (fc2): Linear(in_features=1024, out_features=2, bias=True)\n",
      "    (relu): ReLU()\n",
      "    (max_pool2d): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(temp_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brf_cqESyk5i",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "brf_cqESyk5i",
    "outputId": "a6f67377-96f8-4492-f277-e1f80964e5c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1213, 16, 2) (1213, 16)\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "prediction = []\n",
    "temp_model.eval()\n",
    "with torch.no_grad():\n",
    "    for idx, (data, target) in enumerate(test_dataloader):\n",
    "        output = temp_model(data)\n",
    "        output_sm = nn.Softmax(dim=1)(output)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        prediction.append(predicted)\n",
    "        result.append(output_sm)\n",
    "        \n",
    "result = torch.stack(result).detach().cpu().numpy()\n",
    "prediction = torch.stack(prediction).detach().cpu().numpy()\n",
    "\n",
    "print(result.shape, prediction.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HyeGxhByym09",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HyeGxhByym09",
    "outputId": "3c3657cb-d548-4992-bf50-6b6880037eca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       ground truth  NN output   probs 0   probs 1\n",
      "0               0.0          0  0.522608  0.477392\n",
      "1               0.0          1  0.468868  0.531132\n",
      "2               0.0          0  0.505892  0.494108\n",
      "3               0.0          0  0.501319  0.498682\n",
      "4               0.0          0  0.535124  0.464876\n",
      "...             ...        ...       ...       ...\n",
      "19403           0.0          1  0.491070  0.508930\n",
      "19404           0.0          0  0.543705  0.456295\n",
      "19405           0.0          0  0.536882  0.463118\n",
      "19406           0.0          0  0.530265  0.469735\n",
      "19407           0.0          0  0.534099  0.465901\n",
      "\n",
      "[19408 rows x 4 columns]\n",
      "Confusion matrix : \n",
      " [[8487 2325]\n",
      " [  26 8570]]\n",
      "Outcome values : \n",
      " 8487 2325 26 8570\n",
      "Classification report : \n",
      " {'0': {'precision': 0.9969458475273112, 'recall': 0.7849611542730299, 'f1-score': 0.8783441138421733, 'support': 10812}, '1': {'precision': 0.7865993575034419, 'recall': 0.9969753373662168, 'f1-score': 0.8793802267713303, 'support': 8596}, 'accuracy': 0.8788643858202803, 'macro avg': {'precision': 0.8917726025153765, 'recall': 0.8909682458196233, 'f1-score': 0.8788621703067518, 'support': 19408}, 'weighted avg': {'precision': 0.9037812541511169, 'recall': 0.8788643858202803, 'f1-score': 0.8788030187648359, 'support': 19408}}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "res = pd.DataFrame(result.reshape(-1,2))\n",
    "pred = pd.DataFrame(prediction.reshape(-1))\n",
    "y_test_new = y_test[:result.reshape(-1,2).shape[0]]\n",
    "result_df = pd.DataFrame({'ground truth': y_test_new, 'NN output': prediction.reshape(-1), 'probs 0': res[0], 'probs 1': res[1]})\n",
    "print(result_df)\n",
    "# work out the accuracy and other metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "actual = result_df['ground truth']\n",
    "predicted = result_df['NN output']\n",
    "# confusion matrix\n",
    "matrix = confusion_matrix(actual, predicted, labels=[0,1])\n",
    "print('Confusion matrix : \\n',matrix)\n",
    "\n",
    "# outcome values order in sklearn\n",
    "tp, fn, fp, tn = confusion_matrix(actual, predicted, labels=[0,1]).reshape(-1)\n",
    "print('Outcome values : \\n', tp, fn, fp, tn)\n",
    "\n",
    "# classification report for precision, recall f1-score and accuracy\n",
    "matrix_2 = classification_report(actual,predicted,labels=[0,1], output_dict=True)\n",
    "print('Classification report : \\n',matrix_2)\n",
    "\n",
    "matrix_df = pd.DataFrame(matrix_2).transpose()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "j400sWG3L22J",
   "metadata": {
    "id": "j400sWG3L22J"
   },
   "outputs": [],
   "source": [
    "def save_results(model_node):\n",
    "    result_df.to_csv(save_path + \"calibrated_softmax/result_probs_3conv_\"+ \"node\"+ str(model_node)+ \"conv\" + \"_calibrated.csv\")\n",
    "    matrix_df.to_csv(save_path + \"calibrated_softmax/classification_report_3conv\" + \"node\"+str(model_node)+ \"conv\" +\".csv\", header=True, index=True)\n",
    "    print(\"model \" + str(model_node) + \" results saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oKuduYdcc_1S",
   "metadata": {
    "id": "oKuduYdcc_1S"
   },
   "outputs": [],
   "source": [
    "if model_node == 1:\n",
    "  save_results(1)\n",
    "elif model_node == 2:\n",
    "  save_results(2)\n",
    "elif model_node == 3:\n",
    "  save_results(3)\n",
    "elif model_node == 4:\n",
    "  save_results(4)\n",
    "elif model_node == 5:\n",
    "  save_results(5)\n",
    "elif model_node == 6:\n",
    "  save_results(6)\n",
    "elif model_node == 7:\n",
    "  save_results(7)\n",
    "elif model_node == 23:\n",
    "  result_df.to_csv(save_path + \"calibrated_softmax/result_probs_3conv_modelreuse_node23model_on_node1_calibrated.csv\")\n",
    "  matrix_df.to_csv(save_path + \"calibrated_softmax/classification_report_3conv_modelreuse_node23model_on_node1.csv\", header=True, index=True)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "temperature scaling.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
